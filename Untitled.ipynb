{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd262152",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4040158366.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Pedro Vidales\\AppData\\Local\\Temp\\ipykernel_18336\\4040158366.py\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    Seguimos viendo una frase común de que el 80% del trabajo de un científico de datos es la limpieza de datos. No tenemos idea de si este número es exacto, pero un científico de datos dedica mucho tiempo y esfuerzo a recopilar, limpiar y preparar los datos para el análisis. Esto se debe a que los conjuntos de datos suelen ser desordenados y complejos por naturaleza. Es una habilidad muy importante para un científico de datos refinar y reestructurar conjuntos de datos en un estado utilizable para pasar a la etapa de análisis de datos.\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Laboratorio | Limpieza de datos\n",
    "\n",
    "## Introducción\n",
    "\n",
    "Seguimos viendo una frase común de que el 80% del trabajo de un científico de datos es la limpieza de datos. No tenemos idea de si este número es exacto, pero un científico de datos dedica mucho tiempo y esfuerzo a recopilar, limpiar y preparar los datos para el análisis. Esto se debe a que los conjuntos de datos suelen ser desordenados y complejos por naturaleza. Es una habilidad muy importante para un científico de datos refinar y reestructurar conjuntos de datos en un estado utilizable para pasar a la etapa de análisis de datos.\n",
    "\n",
    "En este ejercicio, practicará las técnicas de limpieza de datos que analizamos en la lección y aprenderá nuevas técnicas buscando documentación y referencias. Trabajarás por tu cuenta pero recuerda que el profesorado está a tu servicio siempre que tengas problemas.\n",
    "\n",
    "## Empezando\n",
    "\n",
    "Ahora ya debería estar familiarizado con el flujo de trabajo para resolver y enviar los laboratorios. Pero en caso de que no, revise las pautas en `README.md` en [repo root](../..) y [previous lab](../lab-pandas).\n",
    "\n",
    "En esta práctica de laboratorio, trabajará en [main.ipynb](su-código/main.ipynb). Para iniciarlo, primero navegue al directorio que contiene `main.ipynb` en la Terminal, luego ejecute `jupyter notebook`. En la página web que se abre automáticamente, haga clic en el enlace `main.ipynb` para iniciarlo.\n",
    "\n",
    "Cuando esté en `main.ipynb`, lea las instrucciones para cada celda y proporcione sus respuestas. Asegúrese de probar sus respuestas en cada celda y guardar. Jupyter Notebook debería guardar automáticamente el progreso de su trabajo. Pero es una buena idea guardar periódicamente su trabajo de forma manual por si acaso.\n",
    "\n",
    "## Metas\n",
    "\n",
    "Obtenga un conjunto de datos completamente limpio.\n",
    "\n",
    "## Entregables\n",
    "\n",
    "- `main.ipynb` completado.\n",
    "- `vehicles_messy-clean.csv` que contiene el conjunto de datos limpio.\n",
    "\n",
    "## Envío\n",
    "\n",
    "Al finalizar, agregue sus entregables a git. Luego confirme git, empuje a su repositorio bifurcado y cree la solicitud de extracción como en los laboratorios anteriores. **RECORDAR\n",
    "\n",
    "- Al finalizar, confirme su código y envíelo a github. **RECUERDA QUE YA HAS FORKED EL REPO ANTES**!!\n",
    "\n",
    "  ```\n",
    "  agrega git\n",
    "  git commit -m \"<nombre de laboratorio o proyecto>\"\n",
    "  maestro de origen git push\n",
    "  ```\n",
    "\n",
    "- Navegue a su repositorio y [cree una solicitud de extracción] (https://help.github.com/articles/creating-a-pull-request/).\n",
    "- Cree una solicitud de extracción con el título siguiendo este formato: **\"[<su_campus>][<bootcamp_code>] [<lab/project_name>]<su_nombre>\"**\n",
    "  - Por ejemplo, si estás haciendo un bootcamp de datos en Madrid, tu nombre es Marc Pomar y el laboratorio en el que estás trabajando es `lab-numpy`, tu solicitud de extracción debería llamarse así: \"[MAD][datamad10108] [lab -numpy] Marc Pomar\"\n",
    "- Si ha creado con éxito la solicitud de extracción, ¡ha terminado! FELICITACIONES :)\n",
    "\n",
    "## Recursos\n",
    "[Data Cleaning Tutorial](https://www.tutorialspoint.com/python/python_data_cleansing.html)\n",
    "\n",
    "[Data Cleaning with Numpy and Pandas](https://realpython.com/python-data-cleaning-numpy-pandas/#python-data-cleaning-recap-and-resources)\n",
    "\n",
    "[Data Cleaning Video](https://www.youtube.com/watch?v=ZOX18HfLHGQ)\n",
    "\n",
    "[Data Preparation](https://www.kdnuggets.com/2017/06/7-steps-mastering-data-preparation-python.html)\n",
    "\n",
    "[Google Search](https://www.google.es/search?q=how+to+clean+data+with+python)\n",
    "\n",
    "                                      ## Desafíos adicionales para los nerds\n",
    "\n",
    "Si has completado el desafío `Estadísticas` sin mucha dificultad, puedes intentar ordenar los datos que encontrarás en la carpeta del laboratorio [weather](../weather-raw.csv). Este conjunto de datos es un subconjunto de un conjunto de datos de red de climatología histórica mundial. Los datos representan los registros meteorológicos diarios de una estación meteorológica (MX17004) en México durante cinco meses en 2010. El objetivo de este desafío adicional es obtener el conjunto de datos más ordenado que pueda producir. **Sugerencia: las variables se almacenan tanto en filas como en columnas.**\n",
    "\n",
    "Para lograr este desafío, deberá investigar un poco sobre ordenar y derretir y pivotar. Siéntase libre de hacer referencia a cualquier recurso que considere apropiado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a87c27b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2154896051.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Pedro Vidales\\AppData\\Local\\Temp\\ipykernel_18336\\2154896051.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    Limpieza de datos\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Limpieza de datos\n",
    "Objetivos de laboratorio\n",
    "\n",
    "Examine los datos en busca de posibles problemas.\n",
    "Identifica y completa los valores faltantes.\n",
    "Identificar y corregir valores incorrectos.\n",
    "Eliminar columnas de baja varianza.\n",
    "Identificar posibles valores atípicos.\n",
    "Corrija los tipos de datos incorrectos.\n",
    "Elimina caracteres especiales y limpia variables categóricas.\n",
    "Identificar y eliminar registros duplicados.\n",
    "Introducción\n",
    "\n",
    "Cuando trabaje con conjuntos de datos, encontrará que a menudo requieren un poco de limpieza. Ya sea que Pandas haya \n",
    "leído originalmente los tipos de datos incorrectamente, los registros estén duplicados, los datos contengan caracteres \n",
    "especiales o valores faltantes, o haya referencias ligeramente diferentes a la misma entidad, cada analista de datos debe \n",
    "saber cómo limpiar los datos con los que está trabajando antes de analizarlos. . En esta lección, aprenderá sobre algunos \n",
    "de los problemas más comunes que desordenan los datos y los métodos para corregir esos problemas y limpiar sus datos.\n",
    "\n",
    "El conjunto de datos que usaremos para esta lección es una versión desordenada del conjunto de datos de vehículos con el que\n",
    "trabajamos en la lección anterior. Importemos esta versión de nuestro conjunto de datos para que luego podamos practicar su\n",
    "limpieza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0dc79a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caef0311",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/vehicles_messy.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18336\\2880760202.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/vehicles_messy.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/vehicles_messy.csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../data/vehicles_messy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2d9e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "Examinar los datos en busca de posibles problemas\n",
    "Una de las primeras cosas que queremos hacer es examinar los datos y buscar posibles problemas. Algunas de las cosas que \n",
    "nos interesa identificar en los datos en esta etapa incluyen:\n",
    "\n",
    "Valores faltantes\n",
    "Caracteres especiales\n",
    "Valores incorrectos\n",
    "Valores extremos o valores atípicos\n",
    "Registros duplicados\n",
    "Tipos de datos incorrectos\n",
    "La presencia de estos puede causar problemas a la hora de analizar los datos, por lo que queremos asegurarnos de abordarlos\n",
    "de antemano. Podemos comenzar inspeccionando visualmente los datos usando el método .head, que nos mostrará las primeras 5 \n",
    "filas de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c809bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Valores faltantes\n",
    "Desde esta vista inicial, podemos ver que nuestro conjunto de datos contiene algunas columnas a las que les faltan valores y\n",
    "otras que parecen tener muchos valores cero.\n",
    "\n",
    "Veamos qué tan frecuentes son los valores faltantes en nuestros datos. Podemos usar el método Pandas .isnull() para \n",
    "verificar si falta el valor en cada campo (null) y devolver True o False para cada campo.\n",
    "\n",
    "Podemos usar el método .sum() para sumar el número de valores verdaderos por columna, y luego podemos agregar una condición\n",
    "usando corchetes que filtrarán los datos y nos mostrarán solo las columnas donde el número de valores nulos fue mayor que \n",
    "cero ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c170a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Elimina las columnas que tienen más de 10,000 valores nulos en ellas\n",
    "En Pandas, podemos hacerlo usando el método drop. Para nuestros propósitos, eliminemos las columnas que tienen más \n",
    "de 10 000 valores nulos. Agregaremos estos nombres de columna a una lista, y luego pasaremos esas columnas al método de \n",
    "eliminación e indicaremos que queremos que se eliminen las columnas (no las filas) configurando el parámetro del eje en 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6281e179",
   "metadata": {},
   "outputs": [],
   "source": [
    "Esto nos deja con solo un puñado de columnas restantes que tienen valores nulos. De las columnas que quedan, parece que la \n",
    "columna de cilindros y la columna de visualización tienen un número similar de valores nulos. Tal vez faltan por razones \n",
    "similares. Podemos investigar esto dividiendo el conjunto de datos en subconjuntos y observando solo los registros donde \n",
    "displ es nulo y solo las columnas que creemos que serán informativas para permitirnos determinar una razón."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de93c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de732ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
